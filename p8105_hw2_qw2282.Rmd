---
title: "P8105_hw2_qw2282"
author: "Qinyao Wu"
date: "9/28/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Import data from the class dataset.
library(tidyverse)
library(p8105.datasets)
```

```{r Problem1}
#Import the data
nyc_transit_data = read.csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, starts_with("ada")) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
  
```

This data set contains variables, which are  `r colnames(nyc_transit_data)`. These data are stored in a dataframe with  `r nrow(nyc_transit_data)` rows and `r ncol(nyc_transit_data)` columns. Up until now, I have cleaned up the variable names right after I imported the data from the data file. And I select the important columns and disregard the rest. and I have recode the content under the entry variable by changing the "Yes" and "No" into logical values TRUE and FALSE. These data are not tidy yet because the there still a lot of unnecessary variables, such as the eleven different routes that can be combined into one variable. 


```{r problem 1}
#Find distinct stations. 
distinct_station = distinct(nyc_transit_data, station_name, line,  .keep_all = TRUE)
dim(distinct_station)  #465 distinct stations that have different station name, route and lines.

ada_com_distinction_station = filter(distinct_station, ada == TRUE)
dim(ada_com_distinction_station) #84 are ada complimented among these different stations. 

#Find the stations that do not have vending machine.
without_vending = filter(nyc_transit_data, vending == "NO")
without_vending_allow_entry = 
  filter(nyc_transit_data, vending == "NO", entry == TRUE)

#Calculate proportion
proportion = nrow(without_vending_allow_entry) / nrow(without_vending) #37.7%
```

There are a total of `r nrow(distinct_station)` different stations, some of them are on the same street but serving different routes and lines. `r nrow(ada_com_distinction_station)` of these distinct stations are ADA compliant. `r proportion*100`% of station entrances/ exits without vending that allow entrance. 

```{r}
#Combine the columns of routes the station serves.
transitdata_tidy = gather(nyc_transit_data, key = route_number, value = route_name, route1:route11)

#Calculate the station that serves A train. 
station_A_route = 
  distinct(transitdata_tidy, station_name, line, .keep_all = TRUE) %>% 
  filter(route_name == "A") %>% #60 distinct stations serve A
  filter(ada == TRUE) #17 of them have ada.

```

There are a total of 60 distinct stations serve the A train. Of these stations, `r nrow(station_A_route)` are ADA complimant. 




##Problem 2
```{r problem 2}

#Import the data for Mr. trash wheeel and do the initial cleaning of the names. 
trash_wheel_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = "A2:N338") %>% 
  janitor::clean_names() 

#Omit the lines without dumpster data, then round the number of sports balls. 
trash_wheel_data = filter(trash_wheel_data, !is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, 0)))

#Import the data for precpitation 2016.
precipitation_2016 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(total)) %>% #Omit the lines without precipitation data. 
  mutate(year = 2016) #Add a variable of year. 
 
#Import the data for precpitation 2017. 
precipitation_2017 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(total)) %>% #Omit the lines without precipitation data. 
  mutate(year = 2017) #Add a variable of year. 

#Combine preciptation 2016 and 2017. 
precipitation_tidy = bind_rows(precipitation_2016, precipitation_2017) %>%
  janitor::clean_names() %>% 
  mutate(month = month.name[month])

```

Mr. Trash Wheel data is stored in a dataframe with `r nrow(trash_wheel_data)` rows and `r ncol(trash_wheel_data)` columns. The dataset contains the following variables: `r colnames(trash_wheel_data)`. The rows indicates there are a total of `r nrow(trash_wheel_data)` observations from `r head(trash_wheel_data$year, 1)`. Some key variables are the types of trash, such as the sports balls and cigaratte butts can all be catagorized into types of trash that Mr. Trash Wheel collected. In addition to the types of trash, the amount of trash can also be a key value because weight_tons and volume_cubic_yards can be catagrized.

The precipitations for 2016 and 2017 are stored in two different dataframe.The dataframe of 2016 contains `r nrow(precipitation_2016)` rows and `r ncol(precipitation_2016)` columns. The dataframe of 2016 contains `r nrow(precipitation_2017)` rows and `r ncol(precipitation_2017)` columns. They both containing the following variables: `r colnames(precipitation_2016)`. I omitted rows that do not have precipitation data. Two dataframes for precipitation are combined and a new precipitation_tidy dataframe is created. The total precipitation in 2017 is `r sum(filter(precipitation_tidy, year == 2017)$total)`. The median number of sports balls in the dumster in 2016 is `r median(filter(trash_wheel_data, year == 2016)$sports_balls)`. 


##Problem 3
```{r problem 3}
#Import the data. 
data(brfss_smart2010)

#Clean the variable names. 
brfss_smart2010 = janitor::clean_names(brfss_smart2010) %>% 
  filter(topic == "Overall Health") %>% #Focus on the overall health topic. 
  select(-c(topic, class, question, sample_size, confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>%  #Clean the names again 
  mutate(proportion = (excellent + very_good) / (excellent + very_good + good + fair + poor)) #Calculate the proportions and add it as a variable. 


#Calculaye unique locations
distinct_location = distinct(brfss_smart2010, locationdesc, .keep_all = TRUE) #total of 404 different locations

distinct_state = distinct(brfss_smart2010, locationabbr, .keep_all = TRUE) #51 states. 

tail(names(sort(table(brfss_smart2010$locationabbr))), 1) #NJ is the most frequently appeared states.

ggplot(filter(brfss_smart2010, year == 2002), aes(x = excellent)) + geom_histogram()


ggplot(filter(brfss_smart2010, locationdesc == "NY - New York County" | locationdesc == "NY - Queens County"), aes(x = year, y = excellent)) + geom_point(aes(color = locationdesc), alpha = .5)
```

There are a total of `r nrow(distinct_location)` locations are included in the dataset. And there are `r nrow(distinct_state)` states. Since there are a total of 51 states, including the district of columbia, in United States, all the states are represented in this dataset. In 2002, the median of the "Excellent" response value are `r median(filter(brfss_smart2010, year == 2002)$excellent, na.rm = TRUE)`.




